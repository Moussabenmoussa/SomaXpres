import os
import requests
import base64
import struct
from groq import Groq

# ---------------------------------------------------------
# ğŸ‘‡ Ø¶Ø¹ Ù…ÙØ§ØªÙŠØ­Ùƒ Ù‡Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©
MY_GROQ_KEY = "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" 
MY_GEMINI_KEY = "AIzaSyCKKXguNfvGNCEaoC6oQF0mu05UEXtPI9M"
# ---------------------------------------------------------

PERSONAS = {
    "amine": { "name": "Ø£Ù…ÙŠÙ†", "voice_id": "Puck", "style": "Ø´Ø§Ø¨ Ø¬Ø²Ø§Ø¦Ø±ÙŠ Ø¹ÙÙˆÙŠØŒ Ø¹Ù…Ù„ÙŠ ÙˆØ³Ø±ÙŠØ¹." },
    "sarah": { "name": "Ø³Ø§Ø±Ø©", "voice_id": "Leda", "style": "ÙØªØ§Ø© Ù„Ø·ÙŠÙØ© ÙˆØ¬Ø°Ø§Ø¨Ø©." },
    "nadir": { "name": "Ù†Ø°ÙŠØ±", "voice_id": "Fenrir", "style": "Ø±Ø³Ù…ÙŠ ÙˆÙ…Ø­ØªØ±Ù…." }
}

class AIAgent:
    def __init__(self, groq_key=None, gemini_key=None):
        self.groq_key = MY_GROQ_KEY
        self.gemini_key = MY_GEMINI_KEY
        
        if self.groq_key and "gsk_" in self.groq_key:
            self.groq_client = Groq(api_key=self.groq_key)
        else:
            self.groq_client = None

    def think_and_speak(self, user_input, history, product_context, merchant_rules, persona="amine", input_type="text"):
        if not self.groq_client:
            return { "text": "ÙŠØ§ Ø´Ø±ÙŠÙƒÙŠØŒ ØªØ£ÙƒØ¯ Ù…Ù† Ù…ÙØªØ§Ø­ Groq ÙÙŠ Ø§Ù„ÙƒÙˆØ¯!", "audio": None }

        selected_persona = PERSONAS.get(persona, PERSONAS["amine"])
        
        # ğŸ”¥ Ù‡Ø°Ø§ Ù‡Ùˆ "Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ø¬Ø¯ÙŠØ¯" (Checklist System)
        system_prompt = f"""
        Ø£Ù†Øª '{selected_persona['name']}'ØŒ Ø¨Ø§Ø¦Ø¹ Ù…Ø­ØªØ±Ù Ù‡Ø¯ÙÙ‡ Ø§Ù„ÙˆØ­ÙŠØ¯: **ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø·Ù„Ø¨ÙŠØ©**.
        Ø§Ù„Ù…Ù†ØªØ¬: {product_context}
        
        ğŸš¨ **Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ (Ø·Ø¨Ù‚Ù‡Ø§ Ø¨ØµØ±Ø§Ù…Ø©):**
        1. **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø©:** Ø§Ù‚Ø±Ø£ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©. Ù…Ø§Ø°Ø§ ÙŠÙ†Ù‚ØµÙ†Ø§ØŸ (Ø§Ù„Ø¹Ù†ÙˆØ§Ù†ØŸ Ø£Ù… Ø§Ù„Ù‡Ø§ØªÙØŸ).
        2. **Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1 (Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©):** Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù„Ø¯ÙŠÙƒ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† -> Ø§Ø·Ù„Ø¨ Ø§Ù„ÙˆÙ„Ø§ÙŠØ© ÙˆØ§Ù„Ø¨Ù„Ø¯ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø©.
        3. **Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2 (Ø§Ù„ÙˆØ³Ø·):** Ø¥Ø°Ø§ Ø£Ø¹Ø·Ø§Ùƒ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† -> Ø§Ø·Ù„Ø¨ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ ÙÙˆØ±Ø§Ù‹ (Ù…Ø«Ø§Ù„: "ØµØ­ÙŠØªØŒ ÙˆØ§Ø´ Ù‡Ùˆ Ø±Ù‚Ù… Ù‡Ø§ØªÙÙƒØŸ").
        4. **Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3 (Ø§Ù„Ù†Ù‡Ø§ÙŠØ©):** Ø¥Ø°Ø§ Ø£Ø¹Ø·Ø§Ùƒ Ø§Ù„Ù‡Ø§ØªÙ -> Ø£ÙƒØ¯ Ø§Ù„Ø·Ù„Ø¨ Ø¨ÙƒÙ„Ù…Ø© "Ø³ÙŠ Ø¨ÙˆÙ†" ÙˆØ£ØºÙ„Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.
        
        â›” **Ù…Ù…Ù†ÙˆØ¹Ø§Øª Ù‚Ø§ØªÙ„Ø©:**
        - **Ù„Ø§ ØªØ±Ø­Ø¨ Ù…Ø±ØªÙŠÙ†:** Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù‚Ø¯ Ø¨Ø¯Ø£ØªØŒ Ù„Ø§ ØªÙ‚Ù„ "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø£Ù†Ø§ Ø£Ù…ÙŠÙ†" Ù…Ø±Ø© Ø£Ø®Ø±Ù‰. Ø§Ø¯Ø®Ù„ ÙÙŠ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹.
        - **Ù„Ø§ ØªØ°ÙƒØ± Ø§Ù„Ø³Ø¹Ø±:** Ø¥Ù„Ø§ Ø¥Ø°Ø§ Ø³Ø£Ù„Ùƒ Ø§Ù„Ø²Ø¨ÙˆÙ† Ø¹Ù†Ù‡ ØµØ±Ø§Ø­Ø©.
        - **Ù„Ø§ ØªÙÙ„Ø³Ù:** Ø±Ø¯ Ø¨Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø© Ù‚ØµÙŠØ±Ø© (Ø£Ù‚Ù„ Ù…Ù† 15 ÙƒÙ„Ù…Ø©).
        - **Ø§Ù„Ø¹Ù†ÙˆØ§Ù†:** Ø¥Ø°Ø§ Ù‚Ø§Ù„ "Ø¨Ø³ÙƒØ±Ø©"ØŒ Ù„Ø§ ØªÙ‚Ù„ "Ø¨Ø³ÙƒØ±Ø© Ø¬Ù…ÙŠÙ„Ø©"ØŒ Ø¨Ù„ Ù‚Ù„ "ÙˆÙŠÙ† Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙÙŠ Ø¨Ø³ÙƒØ±Ø©ØŸ" Ø£Ùˆ "Ù‡Ø§Øª Ø±Ù‚Ù…Ùƒ".

        Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙƒÙ„Ø§Ù…: {selected_persona['style']}
        """

        messages = [{"role": "system", "content": system_prompt}]
        # Ù†Ø±Ø³Ù„ ÙƒÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„ÙŠØ¹Ø±Ù Ø§Ù„Ø±ÙˆØ¨ÙˆØª Ø£ÙŠÙ† ÙˆØµÙ„Ù†Ø§ (ÙˆÙ„ÙŠØ³ Ø¢Ø®Ø± 4 ÙÙ‚Ø· Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø²Ù‡Ø§ÙŠÙ…Ø±)
        messages.extend(history) 
        messages.append({"role": "user", "content": user_input})

        try:
            # 1. Ø§Ù„ØªÙÙƒÙŠØ± (Groq)
            completion = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=messages,
                max_tokens=60, # ØªÙ‚ÙŠÙŠØ¯ Ø§Ù„Ø±Ø¯ Ù„ÙŠÙƒÙˆÙ† Ù‚ØµÙŠØ±Ø§Ù‹ Ø¬Ø¯Ø§Ù‹
                temperature=0.3 # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª
            )
            ai_text = completion.choices[0].message.content

            # 2. Ø§Ù„ØªØ­Ø¯Ø« (Gemini)
            audio_b64 = None
            if input_type == "voice" and self.gemini_key:
                raw_audio = self.generate_audio_raw(ai_text, selected_persona['voice_id'])
                if raw_audio:
                    audio_b64 = self.add_wav_header(raw_audio)

            return { "text": ai_text, "audio": audio_b64 }

        except Exception as e:
            print(f"âŒ Error: {e}")
            return {"text": "Ø³Ù…Ø­Ù„ÙŠØŒ Ø¹Ø§ÙˆØ¯ Ù‚ÙˆÙ„ÙŠØŸ", "audio": None}

    def generate_audio_raw(self, text, voice_name):
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key={self.gemini_key}"
        payload = {
            "contents": [{ "parts": [{ "text": text }] }],
            "generationConfig": {
                "responseModalities": ["AUDIO"],
                "speechConfig": { "voiceConfig": { "prebuiltVoiceConfig": { "voiceName": voice_name } } }
            }
        }
        try:
            response = requests.post(url, json=payload)
            if response.status_code == 200:
                b64_data = response.json()['candidates'][0]['content']['parts'][0]['inlineData']['data']
                return base64.b64decode(b64_data)
            return None
        except:
            return None

    def add_wav_header(self, pcm_data, sample_rate=24000):
        num_channels = 1
        bits_per_sample = 16
        byte_rate = sample_rate * num_channels * bits_per_sample // 8
        block_align = num_channels * bits_per_sample // 8
        data_size = len(pcm_data)
        header = struct.pack('<4sI4s4sIHHIIHH4sI', b'RIFF', 36 + data_size, b'WAVE', b'fmt ', 16, 1, num_channels, sample_rate, byte_rate, block_align, bits_per_sample, b'data', data_size)
        return base64.b64encode(header + pcm_data).decode('utf-8')
