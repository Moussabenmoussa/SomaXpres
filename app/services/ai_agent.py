import os
import requests
import base64
import struct
from groq import Groq

# ---------------------------------------------------------
# ğŸ‘‡ Ø¶Ø¹ Ù…ÙØ§ØªÙŠØ­Ùƒ Ù‡Ù†Ø§
MY_GROQ_KEY = "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" 
MY_GEMINI_KEY = "AIzaSyCKKXguNfvGNCEaoC6oQF0mu05UEXtPI9M"
# ---------------------------------------------------------



PERSONAS = {
    "amine": { "name": "Ø£Ù…ÙŠÙ†", "voice_id": "Puck", "style": "Ø´Ø§Ø¨ Ø¬Ø²Ø§Ø¦Ø±ÙŠ Ø­Ø±ÙŠØµ ÙˆÙØ§Ù‡Ù…." },
    "sarah": { "name": "Ø³Ø§Ø±Ø©", "voice_id": "Leda", "style": "ÙØªØ§Ø© Ù…Ù†Ø¸Ù…Ø© ÙˆØ¯Ù‚ÙŠÙ‚Ø©." },
    "nadir": { "name": "Ù†Ø°ÙŠØ±", "voice_id": "Fenrir", "style": "Ø±Ø³Ù…ÙŠ ÙˆÙ…Ø¯Ù‚Ù‚." }
}

class AIAgent:
    def __init__(self, groq_key=None, gemini_key=None):
        self.groq_key = MY_GROQ_KEY
        self.gemini_key = MY_GEMINI_KEY
        
        if self.groq_key and "gsk_" in self.groq_key:
            self.groq_client = Groq(api_key=self.groq_key)
        else:
            self.groq_client = None

    def think_and_speak(self, user_input, history, product_context, merchant_rules, persona="amine", input_type="text"):
        if not self.groq_client:
            return { "text": "Ø§Ù„Ù…ÙØªØ§Ø­ Ù†Ø§Ù‚Øµ.", "audio": None }

        selected_persona = PERSONAS.get(persona, PERSONAS["amine"])
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ù†Øµ Ù„Ù„Ø¨Ø­Ø« ÙÙŠÙ‡ Ø¹Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        history_text = str(history) + " " + user_input
        
        # ğŸ”¥ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù…ØµÙØ­ (The Armored Prompt)
        system_prompt = f"""
        Ø£Ù†Øª '{selected_persona['name']}'ØŒ Ø¨Ø§Ø¦Ø¹ Ø¬Ø²Ø§Ø¦Ø±ÙŠ Ù„Ø§ ÙŠÙ‚Ø¨Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡.
        Ø§Ù„Ù…Ù†ØªØ¬: {product_context}
        
        ğŸš¨ **Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµØ§Ø±Ù… (Number Law):**
        - Ø§Ù†Ø¸Ø± ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©: Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ø±Ù‚Ù… Ù‡Ø§ØªÙ Ø­Ù‚ÙŠÙ‚ÙŠ (Ø£Ø±Ù‚Ø§Ù… Ù…Ø«Ù„ 05, 06, 07)ØŸ
        - **Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø£Ø±Ù‚Ø§Ù…Ø§Ù‹:** Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø·Ù„Ø¨. Ø­ØªÙ‰ Ù„Ùˆ Ù‚Ø§Ù„ Ø§Ù„Ø²Ø¨ÙˆÙ† "Ù†Ø¹Ù…" Ø£Ùˆ "Ø£ÙƒÙŠØ¯" Ø£Ùˆ "Ø§Ø¨Ø¹Ø«".
        - Ø¥Ø°Ø§ Ù‚Ø§Ù„ "Ù†Ø¹Ù…" ÙˆÙ„Ù… ÙŠÙƒØªØ¨ Ø§Ù„Ø±Ù‚Ù…ØŒ Ù‚Ù„ Ù„Ù‡: "**Ø¥ÙŠÙ‡ØŒ Ø¨ØµØ­ Ù…Ø§ Ø¹Ø·ÙŠØªÙ†ÙŠØ´ Ø§Ù„Ø±Ù‚Ù…! Ø£ÙƒØªØ¨Ù‡ÙˆÙ„ÙŠ Ø¨Ø§Ø´ Ù†Ø³Ø¬Ù„Ù‡.**"
        
        ğŸš¨ **Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©:**
        1. **Ø§Ù„ÙØ­Øµ:** Ù‡Ù„ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù‡Ø§ØªÙ (Ø§Ù„Ø£Ø±Ù‚Ø§Ù…) Ù…ÙˆØ¬ÙˆØ¯Ø§Ù†ØŸ
        2. **Ø§Ù„Ù†Ù‚Øµ:** Ø§Ø·Ù„Ø¨ Ù…Ø§ ÙŠÙ†Ù‚Øµ. (Ø¥Ø°Ø§ Ø£Ø¹Ø·Ø§Ùƒ Ø§Ù„ÙˆÙ„Ø§ÙŠØ© ÙÙ‚Ø·ØŒ Ø§Ø·Ù„Ø¨ Ø§Ù„Ù‡Ø§ØªÙ ÙˆØ§Ù„Ø¨Ù„Ø¯ÙŠØ©).
        3. **Ø§Ù„ÙØ® (Ø§Ù„ØªØ£ÙƒÙŠØ¯):**
           - ÙÙ‚Ø· Ø¹Ù†Ø¯Ù…Ø§ ØªÙ…Ù„Ùƒ (Ø§Ù„Ø¹Ù†ÙˆØ§Ù† + Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡Ø§ØªÙ)ØŒ Ù‚Ù„:
           "ØµØ­ÙŠØª. Ù…Ø§Ù„Ø§ [Ø§Ù„Ù…Ù†ØªØ¬] Ù„Ù€ [Ø§Ù„Ø¹Ù†ÙˆØ§Ù†]. Ø§Ù„Ù…ÙˆØ²Ø¹ ÙŠØ¬ÙŠ Ø¹Ù„Ù‰ Ø¬Ø§Ù„ÙƒØŒ **Ø±Ø§Ùƒ ØªÙˆØ¬Ø¯ Ø§Ù„Ø¯Ø±Ø§Ù‡Ù… ÙˆØªØ±Ø¯ Ø¹Ù„ÙŠÙ‡ Ø³ÙŠØ±ØŸ**"
        4. **Ø§Ù„Ø¥ØºÙ„Ø§Ù‚:**
           - Ø¥Ø°Ø§ ÙˆØ§ÙÙ‚ Ø¨Ø¹Ø¯ Ø§Ù„ÙØ® -> "ØªÙ… Ø§Ù„ØªØ£ÙƒÙŠØ¯."

        ØªÙƒÙ„Ù… Ø¨Ø§Ù„Ø¯Ø§Ø±Ø¬Ø© Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠØ© ÙÙ‚Ø·. ÙƒÙ† Ø­Ø§Ø²Ù…Ø§Ù‹ ÙÙŠ Ø·Ù„Ø¨ Ø§Ù„Ø±Ù‚Ù….
        """

        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(history) 
        messages.append({"role": "user", "content": user_input})

        try:
            completion = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=messages,
                max_tokens=90,
                temperature=0.2 # Ø°ÙƒØ§Ø¡ Ø¨Ø§Ø±Ø¯ Ø¬Ø¯Ø§Ù‹ (Ù„Ø§ ÙŠØªØ®ÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©)
            )
            ai_text = completion.choices[0].message.content

            audio_b64 = None
            if input_type == "voice" and self.gemini_key:
                raw_audio = self.generate_audio_raw(ai_text, selected_persona['voice_id'])
                if raw_audio:
                    audio_b64 = self.add_wav_header(raw_audio)

            return { "text": ai_text, "audio": audio_b64 }

        except Exception as e:
            print(f"âŒ Error: {e}")
            return {"text": "ÙƒØ§ÙŠÙ† Ø®Ù„Ù„ØŒ Ø¹Ø§ÙˆØ¯ØŸ", "audio": None}

    def generate_audio_raw(self, text, voice_name):
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key={self.gemini_key}"
        payload = {
            "contents": [{ "parts": [{ "text": text }] }],
            "generationConfig": {
                "responseModalities": ["AUDIO"],
                "speechConfig": { "voiceConfig": { "prebuiltVoiceConfig": { "voiceName": voice_name } } }
            }
        }
        try:
            response = requests.post(url, json=payload)
            if response.status_code == 200:
                b64_data = response.json()['candidates'][0]['content']['parts'][0]['inlineData']['data']
                return base64.b64decode(b64_data)
            return None
        except:
            return None

    def add_wav_header(self, pcm_data, sample_rate=24000):
        num_channels = 1
        bits_per_sample = 16
        byte_rate = sample_rate * num_channels * bits_per_sample // 8
        block_align = num_channels * bits_per_sample // 8
        data_size = len(pcm_data)
        header = struct.pack('<4sI4s4sIHHIIHH4sI', b'RIFF', 36 + data_size, b'WAVE', b'fmt ', 16, 1, num_channels, sample_rate, byte_rate, block_align, bits_per_sample, b'data', data_size)
        return base64.b64encode(header + pcm_data).decode('utf-8')
