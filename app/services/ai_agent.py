import os
import requests
import base64
import struct
from groq import Groq

# ---------------------------------------------------------
# ğŸ‘‡ Ø¶Ø¹ Ù…ÙØ§ØªÙŠØ­Ùƒ Ù‡Ù†Ø§
MY_GROQ_KEY = "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" 
MY_GEMINI_KEY = "AIzaSyCKKXguNfvGNCEaoC6oQF0mu05UEXtPI9M"
# ---------------------------------------------------------

PERSONAS = {
    "amine": { "name": "Ø£Ù…ÙŠÙ†", "voice_id": "Puck", "style": "Ø´Ø§Ø¨ Ø¬Ø²Ø§Ø¦Ø±ÙŠ Ø¬Ø¯ÙŠ ÙˆÙ…Ø­ØªØ±Ù." },
    "sarah": { "name": "Ø³Ø§Ø±Ø©", "voice_id": "Leda", "style": "ÙØªØ§Ø© Ø­Ø§Ø²Ù…Ø© ÙˆÙ„Ø·ÙŠÙØ©." },
    "nadir": { "name": "Ù†Ø°ÙŠØ±", "voice_id": "Fenrir", "style": "Ù…Ø¯Ù‚Ù‚ Ø·Ù„Ø¨Ø§Øª Ø±Ø³Ù…ÙŠ." }
}

class AIAgent:
    def __init__(self, groq_key=None, gemini_key=None):
        self.groq_key = MY_GROQ_KEY
        self.gemini_key = MY_GEMINI_KEY
        
        if self.groq_key and "gsk_" in self.groq_key:
            self.groq_client = Groq(api_key=self.groq_key)
        else:
            self.groq_client = None

    def think_and_speak(self, user_input, history, product_context, merchant_rules, persona="amine", input_type="text"):
        if not self.groq_client:
            return { "text": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ÙØ§ØªÙŠØ­.", "audio": None }

        selected_persona = PERSONAS.get(persona, PERSONAS["amine"])
        
        # ğŸ”¥ Ø¨Ø±ÙˆÙ…Ø¨Øª "Ø¶Ø¯ Ø§Ù„Ø±ÙˆØªÙˆØ±" (Anti-Rotour Protocol)
        system_prompt = f"""
        Ø£Ù†Øª '{selected_persona['name']}'ØŒ Ù„Ø³Øª Ù…Ø¬Ø±Ø¯ Ø¨Ø§Ø¦Ø¹ØŒ Ø£Ù†Øª **Ù…Ø±Ø§Ù‚Ø¨ Ø¬ÙˆØ¯Ø©** Ù‡Ø¯ÙÙƒ ØªØµÙÙŠØ© Ø§Ù„Ø²Ø¨Ø§Ø¦Ù† ØºÙŠØ± Ø§Ù„Ø¬Ø§Ø¯ÙŠÙ†.
        Ø§Ù„Ù…Ù†ØªØ¬: {product_context}
        Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: (Ø§Ù‚Ø±Ø£Ù‡ Ù…Ù† ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù†ØªØ¬ Ø¨Ø¯Ù‚Ø©).
        
        ğŸš¨ **Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø§Ù„ØµØ§Ø±Ù… (Ø·Ø¨Ù‚Ù‡ Ø¨Ø­Ø°Ø§ÙÙŠØ±Ù‡):**
        
        1. **Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¬Ù…Ø¹:** Ø§Ø·Ù„Ø¨ (Ø§Ù„Ø¹Ù†ÙˆØ§Ù† + Ø§Ù„Ù‡Ø§ØªÙ) Ø¥Ø°Ø§ ÙƒØ§Ù†ÙˆØ§ Ù†Ø§Ù‚ØµÙŠÙ†.
        
        2. **Ù…Ø±Ø­Ù„Ø© "Ø§Ù„ÙØ®" (Ø£Ù‡Ù… Ù…Ø±Ø­Ù„Ø©):**
           - Ø¨Ù…Ø¬Ø±Ø¯ Ø­ØµÙˆÙ„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù‡Ø§ØªÙØŒ **ØªÙˆÙ‚Ù! Ù„Ø§ ØªØ¤ÙƒØ¯ Ø§Ù„Ø·Ù„Ø¨ ÙÙˆØ±Ø§Ù‹.**
           - ÙŠØ¬Ø¨ Ø£Ù† ØªÙ‚ÙˆÙ… Ø¨Ù€ "Ø§Ù„ØªÙ„Ø®ÙŠØµ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ".
           - Ù‚Ù„: "ØªÙ…Ø§Ù…. Ù„Ù„ØªØ£ÙƒÙŠØ¯: Ø·Ù„Ø¨ÙŠØªÙƒ Ù„Ù€ [Ø§Ù„Ø¹Ù†ÙˆØ§Ù†] Ø¨Ø³Ø¹Ø± [Ø§Ù„Ø³Ø¹Ø±]. **Ø®ÙˆÙŠØ§ØŒ Ø§Ù„Ù…ÙˆØ²Ø¹ ÙŠØ®Ù„Øµ Ø­Ù‚ Ø§Ù„Ø·Ø±ÙŠÙ‚ØŒ Ø±Ø§Ùƒ Ù…ØªØ£ÙƒØ¯ 100% ØªÙƒÙˆÙ† ÙˆØ§Ø¬Ø¯ ÙˆØªØ±Ø¯ Ø¹Ù„ÙŠÙ‡ØŸ**"
        
        3. **Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø®ØªØ§Ù…:**
           - Ø¥Ø°Ø§ Ù‚Ø§Ù„ "Ù†Ø¹Ù…" Ø£Ùˆ "Ø£ÙƒÙŠØ¯" -> Ù‚Ù„: "ØªÙ… ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø·Ù„Ø¨ Ø±Ø³Ù…ÙŠØ§Ù‹. Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ù„ØªØ²Ø§Ù…Ùƒ."
           - Ø¥Ø°Ø§ ØªØ±Ø¯Ø¯ Ø£Ùˆ Ù‚Ø§Ù„ "Ù†Ø´ÙˆÙ" -> Ù‚Ù„: "Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒÙ†Øª Ù…ØªØ£ÙƒØ¯Ø§Ù‹. Ù‡Ù„ Ù†Ø¹ØªÙ…Ø¯ Ø§Ù„Ø·Ù„Ø¨ØŸ"

        â›” **Ù‚ÙˆØ§Ø¹Ø¯:**
        - Ù„Ø§ ØªÙ‚Ø¨Ù„ "Ø§Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡" ÙƒØ¥Ø¬Ø§Ø¨Ø© Ù†Ù‡Ø§Ø¦ÙŠØ©ØŒ Ø§Ø·Ù„Ø¨ ØªØ£ÙƒÙŠØ¯Ø§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ (Ù†Ø¹Ù…/Ù„Ø§).
        - Ø§Ù†ØªØ²Ø¹ "Ù…ÙˆØ§ÙÙ‚Ø© ØµØ±ÙŠØ­Ø©" Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø± ÙˆØ§Ù„Ø´Ø±Ø§Ø¡.
        - ÙƒÙ† Ø­Ø§Ø²Ù…Ø§Ù‹ ÙˆÙ…Ø¤Ø¯Ø¨Ø§Ù‹ ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª.
        
        Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: {selected_persona['style']}
        """

        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(history) 
        messages.append({"role": "user", "content": user_input})

        try:
            # Ù†Ø±ÙØ¹ Ø¯Ø±Ø¬Ø© "Ø§Ù„Ø°ÙƒØ§Ø¡" Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù„ÙŠÙÙ‡Ù… Ø§Ù„Ù…Ø±Ø§ÙˆØºØ©
            completion = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=messages,
                max_tokens=85,
                temperature=0.3
            )
            ai_text = completion.choices[0].message.content

            audio_b64 = None
            if input_type == "voice" and self.gemini_key:
                raw_audio = self.generate_audio_raw(ai_text, selected_persona['voice_id'])
                if raw_audio:
                    audio_b64 = self.add_wav_header(raw_audio)

            return { "text": ai_text, "audio": audio_b64 }

        except Exception as e:
            print(f"âŒ Error: {e}")
            return {"text": "Ø³Ù…Ø­Ù„ÙŠØŒ Ø§Ù„Ø´Ø¨ÙƒØ©ØŸ", "audio": None}

    def generate_audio_raw(self, text, voice_name):
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key={self.gemini_key}"
        payload = {
            "contents": [{ "parts": [{ "text": text }] }],
            "generationConfig": {
                "responseModalities": ["AUDIO"],
                "speechConfig": { "voiceConfig": { "prebuiltVoiceConfig": { "voiceName": voice_name } } }
            }
        }
        try:
            response = requests.post(url, json=payload)
            if response.status_code == 200:
                b64_data = response.json()['candidates'][0]['content']['parts'][0]['inlineData']['data']
                return base64.b64decode(b64_data)
            return None
        except:
            return None

    def add_wav_header(self, pcm_data, sample_rate=24000):
        num_channels = 1
        bits_per_sample = 16
        byte_rate = sample_rate * num_channels * bits_per_sample // 8
        block_align = num_channels * bits_per_sample // 8
        data_size = len(pcm_data)
        header = struct.pack('<4sI4s4sIHHIIHH4sI', b'RIFF', 36 + data_size, b'WAVE', b'fmt ', 16, 1, num_channels, sample_rate, byte_rate, block_align, bits_per_sample, b'data', data_size)
        return base64.b64encode(header + pcm_data).decode('utf-8')
